# Git代码库

## 目录

- [1 Fundation-Model列表](#1-fundation-model列表)
- [2 BenchMark](#2-benchmark)
- [3 LLM](#3-llm)
- [4 TTS](#4-tts)
- [5 多模态](#5-多模态)
- [6 多任务学习](#6-多任务学习)
- [7 其他深度学习相关](#7-其他深度学习相关)

<br>

## 1 fundation model列表
- https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models#LLM
- https://github.com/wgwang/LLMs-In-China


Awesome Chinese LLM
- https://github.com/HqWu-HITCS/Awesome-Chinese-LLM
> 包括：LLM、多模态LLM、训练&推理框架、数据集、微调框架等


Awesome Pretrained Chinese NLP Models
- https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models
> 各类中文预训练大模型

<br>

## 2 BenchMark

SuperCLUE中文大模型排行榜
- https://www.yuanyu.ai/superclue.html


HuggingFace BenchMark
- https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard


Leaderboard - C-Eval
- https://cevalbenchmark.com/static/leaderboard.html


笔记 - Huggingface LLM 排行榜指标探索
- https://zhuanlan.zhihu.com/p/640880251


LLMs 评测 benchmark 汇总
- https://zhuanlan.zhihu.com/p/638508365


<br>

## 3 LLM

Instruction Tuning with GPT-4
- https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM


LLaMA Factory: Training and Evaluating Large Language Models with Minimal Effort
- https://github.com/hiyouga/LLaMA-Factory


ChatGLM Efficient Tuning
- https://github.com/hiyouga/ChatGLM-Efficient-Tuning


PEFT：State-of-the-art Parameter-Efficient Fine-Tuning (PEFT) methods
- https://github.com/huggingface/peft


vllm
- https://github.com/vllm-project/vllm


Llama 2
- https://github.com/facebookresearch/llama


Llama2-Chinese
- https://github.com/FlagAlpha/Llama2-Chinese


Stanford Alpaca: An Instruction-following LLaMA Model
- https://github.com/tatsu-lab/stanford_alpaca


Cinese-LLaMA-Alpca-2
- https://github.com/ymcui/Chinese-LLaMA-Alpaca


BELLE: Be Everyone's Large Language model Engine
- https://github.com/LianjiaTech/BELLE


ChatGLM Efficient Tuning
- https://github.com/hiyouga/ChatGLM-Efficient-Tuning


Firefly(流萤): 中文对话式大语言模型
- https://github.com/yangjianxin1/Firefly


中国大模型列表
- https://github.com/wgwang/LLMs-In-China


MOSS
- https://github.com/OpenLMLab/MOSS


清华
- https://github.com/THUDM

  - 130B: An Open Bilingual Pre-Trained Model
    https://github.com/THUDM/GLM-130B

  - ChatGLM-6B
    https://github.com/THUDM/ChatGLM-6B
	
  - ChatGLM2-6B
	https://github.com/THUDM/ChatGLM2-6B

    
Baichuan Intelligent Technology
- https://github.com/baichuan-inc

  - Baichuan2：
    https://github.com/baichuan-inc/Baichuan2
	
  - Baichuan-13B：
	https://github.com/baichuan-inc/Baichuan-13B

  - Baichuan-7B：
	https://github.com/baichuan-inc/Baichuan-7B


Qwen
- https://github.com/QwenLM/Qwen


MediaGPT ：中文自媒体大模型
- https://github.com/IMOSR/MediaGPT


<br>

## 4 TTS

MassTTS
- https://github.com/anyvoiceai/MassTTS


Bert-VITS2
- https://github.com/fishaudio/Bert-VITS2


KAN-TTS
- https://github.com/alibaba-damo-academy/KAN-TTS


SAMBERT
- https://modelscope.cn/search?search=SAMBERT
>（来源 model scope）


<br>

## 5 多模态

CLIP
- https://github.com/openai/CLIP


Chinese CLIP
- https://github.com/OFA-Sys/Chinese-CLIP


BLIP
- https://github.com/salesforce/BLIP


albef
- https://github.com/salesforce/ALBEF


<br>

## 6 多任务学习

DeepLearning：多任务学习MTL
- https://github.com/QunBB/DeepLearning


LibMTL：an open-source library built on PyTorch for Multi-Task Learning (MTL)
- https://github.com/median-research-group/LibMTL


Multi-Task Deep Neural Networks for Natural Language Understanding
- https://github.com/namisan/mt-dnn


Awesome Multi-Task Learning：
- https://github.com/Manchery/awesome-multi-task-learning


<br>

## 7 其他深度学习相关

【li mu】深度学习论文精读
- https://github.com/mli/paper-reading


transformers
- https://github.com/huggingface/transformers


bert
- https://github.com/google-research/bert


calflops: a FLOPs and Params calculate tool for neural networks
- https://github.com/MrYxJ/calculate-flops.pytorch


jieba
- https://github.com/fxsjy/jieba

